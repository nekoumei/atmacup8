{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7th place solution (0.8502) + late sub (0.4552)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:37:30.124209Z",
     "start_time": "2020-12-14T12:37:28.165245Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from gensim.models import word2vec\n",
    "import jpholiday\n",
    "import swifter\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "pd.options.display.max_rows = 1000\n",
    "import texthero as hero\n",
    "from texthero import preprocessing as hero_preprocessing\n",
    "from utils import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:37:30.151706Z",
     "start_time": "2020-12-14T12:37:30.125445Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    train = pd.read_csv('../data/train.csv')\n",
    "    test = pd.read_csv('../data/test.csv')\n",
    "    submit = pd.read_csv('../data/atmaCup8_sample-submission.csv')\n",
    "    \n",
    "    return train, test, submit\n",
    "\n",
    "train, test, submit = read_data()\n",
    "# drop nintendo\n",
    "train = train[train['Publisher']!='Nintendo'].reset_index(drop=True)\n",
    "both_exists_developers = list(set(train['Developer'].dropna()) & set(test['Developer'].dropna()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:37:30.186934Z",
     "start_time": "2020-12-14T12:37:30.154551Z"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        self.target_mean_all = {}\n",
    "        self.hero_pipeline = [hero_preprocessing.fillna\n",
    "                       , hero_preprocessing.lowercase\n",
    "                       , hero_preprocessing.remove_digits\n",
    "                       , hero_preprocessing.remove_punctuation\n",
    "                       , hero_preprocessing.remove_diacritics\n",
    "                       , hero_preprocessing.remove_whitespace\n",
    "                      ]\n",
    "\n",
    "        \n",
    "    def target_encoding_train(self, X_train, y_train, col_name, replace=True, target_name=None):\n",
    "        X_train = X_train.copy()\n",
    "        y_train = y_train.copy()\n",
    "        y_train.iloc[:] = np.log1p(y_train)\n",
    "        \n",
    "        # テストデータのカテゴリを変換する\n",
    "        Xy = pd.DataFrame({'trans_col': X_train[col_name], 'target': y_train})\n",
    "        if self.target_mean_all.get(col_name) is None:\n",
    "            self.target_mean_all[col_name] = {}\n",
    "        self.target_mean_all[col_name][target_name] = Xy.groupby('trans_col')['target'].mean()\n",
    "\n",
    "        # trainを変換する\n",
    "        oof_target = np.zeros(X_train.shape[0])\n",
    "        kf = GroupKFold(n_splits=5)\n",
    "        for idx_1, idx_2 in kf.split(X_train, y_train, self.groups):\n",
    "            target_mean = Xy.iloc[idx_1, :].groupby('trans_col')['target'].mean()\n",
    "            oof_target[idx_2] = X_train[col_name].iloc[idx_2].map(target_mean)\n",
    "\n",
    "        if replace:\n",
    "            X_train[col_name] = oof_target\n",
    "        else:\n",
    "            X_train[f'te_{target_name}_{col_name}'] = oof_target\n",
    "\n",
    "        return X_train\n",
    "    \n",
    "    def target_encoding_test(self, X_test, col_name, replace=True, target_name=None):\n",
    "        X_test = X_test.copy()\n",
    "        if replace:\n",
    "            X_test[col_name] = X_test[col_name].map(self.target_mean_all[col_name][target_name])\n",
    "        else:\n",
    "            X_test[f'te_{target_name}_{col_name}'] = X_test[col_name].map(self.target_mean_all[col_name][target_name])\n",
    "        \n",
    "        return X_test\n",
    "    \n",
    "    def groupby_aggregation(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        columns = df.columns.tolist()\n",
    "        if 'Critic_Score_pred' in columns:\n",
    "            for agg_col in tqdm(['Publisher', 'Developer', 'Platform', 'Genre', 'Rating',\n",
    "                                 'Name_Head_1', 'Name_Head_2', 'Name_Head_3',\n",
    "                                 'Year_of_Release',\n",
    "                                 'Bin_Year'\n",
    "                                ]):\n",
    "                agg_df = df.groupby([agg_col]).agg(\n",
    "                    {\n",
    "                        'Critic_Score_pred': ['mean', 'min', 'max', 'std'],\n",
    "                        'Critic_Count_pred': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "                        'User_Score_pred': ['mean', 'min', 'max', 'std'],\n",
    "                        'User_Count_pred': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "                    }\n",
    "                )\n",
    "                flatten_names = agg_df.columns.to_flat_index().tolist()\n",
    "                agg_df.columns = [f'{agg_col}_{valname}_{aggname}' for valname, aggname in flatten_names]\n",
    "                df = df.merge(agg_df, left_on=agg_col, right_index=True, how='left')\n",
    "\n",
    "                # diff\n",
    "                for valname in ['Critic_Score_pred', 'Critic_Count_pred', 'User_Score_pred', 'User_Count_pred']:\n",
    "                    for aggname in ['mean', 'min', 'max']:\n",
    "                        df[f'Diff_{agg_col}_{valname}_{aggname}'] = df[valname] - df[f'{agg_col}_{valname}_{aggname}']\n",
    "        \n",
    "        for agg_col in tqdm(['Publisher', 'Developer', 'Platform', 'Genre', 'Rating',\n",
    "                             'Name_Head_1', 'Name_Head_2', 'Name_Head_3',\n",
    "                             'Year_of_Release',\n",
    "                             'Bin_Year'\n",
    "                            ] + self.concat_cols):\n",
    "            if agg_col not in ['Publisher', 'Developer', 'Year_of_Release', 'Bin_Year']:\n",
    "                agg_df = df.groupby([agg_col]).agg(\n",
    "                    {\n",
    "                        'Critic_Score': ['mean', 'min', 'max', 'std'],\n",
    "                        'Critic_Count': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "                        'User_Score': ['mean', 'min', 'max', 'std'],\n",
    "                        'User_Count': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "                        'Year_of_Release': ['mean', 'min', 'max', 'std']\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                agg_df = df.groupby([agg_col]).agg(\n",
    "                    {\n",
    "                        'Critic_Score': ['mean', 'min', 'max', 'std'],\n",
    "                        'Critic_Count': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "                        'User_Score': ['mean', 'min', 'max', 'std'],\n",
    "                        'User_Count': ['sum', 'mean', 'min', 'max', 'std'],\n",
    "                    }\n",
    "                )\n",
    "            flatten_names = agg_df.columns.to_flat_index().tolist()\n",
    "            agg_df.columns = [f'{agg_col}_{valname}_{aggname}' for valname, aggname in flatten_names]\n",
    "            df = df.merge(agg_df, left_on=agg_col, right_index=True, how='left')\n",
    "            \n",
    "            # diff\n",
    "            for valname in ['Critic_Score', 'Critic_Count', 'User_Score', 'User_Count']:\n",
    "                for aggname in ['mean', 'min', 'max']:\n",
    "                    df[f'Diff_{agg_col}_{valname}_{aggname}'] = df[valname] - df[f'{agg_col}_{valname}_{aggname}']\n",
    "\n",
    "        # count encoding\n",
    "        for agg_col in tqdm(['Platform', 'Genre', 'Rating', 'Year_of_Release', 'Bin_Year'] + self.concat_cols):\n",
    "            count_series = df.groupby(agg_col)['Global_Sales'].count()\n",
    "            count_series.name = f'ce_{agg_col}'\n",
    "            df = df.merge(count_series, left_on=agg_col, right_index=True, how='left')\n",
    "        \n",
    "        # とっぽさんのやつ\n",
    "        genre_pivot = df.pivot_table(index='Publisher', columns='Genre', values='Name', aggfunc='count').fillna(0).reset_index()\n",
    "        plat_pivot = df.pivot_table(index='Publisher', columns='Platform', values='Name', aggfunc='count').fillna(0).reset_index()\n",
    "        year_pivot = df.pivot_table(index='Publisher', columns='Year_of_Release', values='Name', aggfunc='count').fillna(0).reset_index()\n",
    "        rating_pivot = df.pivot_table(index='Publisher', columns='Rating', values='Name', aggfunc='count').fillna(0).reset_index()\n",
    "        pivot_all = genre_pivot.merge(\n",
    "            plat_pivot, on='Publisher').merge(\n",
    "            year_pivot, on='Publisher').merge(\n",
    "            rating_pivot, on='Publisher').set_index('Publisher')\n",
    "        pivot_scaled = StandardScaler().fit_transform(pivot_all)\n",
    "        dimension_size = 10\n",
    "        pca_df = pd.DataFrame(\n",
    "            PCA(n_components=dimension_size, random_state=0).fit_transform(pivot_scaled),\n",
    "            columns=[f'publisher_PCA_{i}' for i in range(dimension_size)],\n",
    "            index=pivot_all.index\n",
    "        )\n",
    "        df = df.merge(pca_df, left_on='Publisher', right_index=True, how='left')\n",
    "        \n",
    "        # とっぽさんのやつ developerばん\n",
    "        genre_pivot = df.pivot_table(index='Developer', columns='Genre', values='Name', aggfunc='count').fillna(0).reset_index()\n",
    "        plat_pivot = df.pivot_table(index='Developer', columns='Platform', values='Name', aggfunc='count').fillna(0).reset_index()\n",
    "        year_pivot = df.pivot_table(index='Developer', columns='Year_of_Release', values='Name', aggfunc='count').fillna(0).reset_index()\n",
    "        rating_pivot = df.pivot_table(index='Developer', columns='Rating', values='Name', aggfunc='count').fillna(0).reset_index()\n",
    "        pivot_all = genre_pivot.merge(\n",
    "            plat_pivot, on='Developer').merge(\n",
    "            year_pivot, on='Developer').merge(\n",
    "            rating_pivot, on='Developer').set_index('Developer')\n",
    "        pivot_scaled = StandardScaler().fit_transform(pivot_all)\n",
    "        dimension_size = 10\n",
    "        pca_df = pd.DataFrame(\n",
    "            PCA(n_components=dimension_size, random_state=0).fit_transform(pivot_scaled),\n",
    "            columns=[f'developer_PCA_{i}' for i in range(dimension_size)],\n",
    "            index=pivot_all.index\n",
    "        )\n",
    "        df = df.merge(pca_df, left_on='Developer', right_index=True, how='left')\n",
    "        \n",
    "         #cha_kabuさんのやつ\n",
    "        def get_top_text_ngrams(corpus, n, g , s):\n",
    "            vec = CountVectorizer(ngram_range=(g, g)).fit(corpus)\n",
    "            bag_of_words = vec.transform(corpus)\n",
    "            sum_words = bag_of_words.sum(axis=0) \n",
    "            words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items() if sum_words[0, idx] > s]\n",
    "            words_freq =sorted(words_freq, key = lambda x: x[1], reverse=False)\n",
    "            return words_freq[:n]\n",
    "#\n",
    "        clean_name = hero.clean(df['Name'], pipeline=self.hero_pipeline)\n",
    "#\n",
    "        most_common_bi = get_top_text_ngrams(clean_name,10000,2,5)\n",
    "        most_common_bi = dict(most_common_bi)\n",
    "#\n",
    "        df[\"cha_kabu_num_Series_bigram\"] = 0\n",
    "        for i in most_common_bi:\n",
    "            idx = df[clean_name.str.contains(i)].index\n",
    "            df.iloc[idx, -1] = most_common_bi[i]\n",
    "        \n",
    "        df['Series_Name_bigram'] = np.nan\n",
    "        for i, name in tqdm(enumerate(clean_name.values)):\n",
    "            for series_name in most_common_bi:\n",
    "                if series_name in name:\n",
    "                    df.iloc[i, -1] = series_name\n",
    "#\n",
    "        most_common_bi = get_top_text_ngrams(clean_name,10000,3,5)\n",
    "        most_common_bi = dict(most_common_bi)\n",
    "#\n",
    "        df[\"cha_kabu_num_Series_trigram\"] = 0\n",
    "        for i in most_common_bi:\n",
    "            idx = df[clean_name.str.contains(i)].index\n",
    "            df.iloc[idx, -1] = most_common_bi[i]\n",
    "        \n",
    "        df['Series_Name_trigram'] = np.nan\n",
    "        for i, name in tqdm(enumerate(clean_name.values)):\n",
    "            for series_name in most_common_bi:\n",
    "                if series_name in name:\n",
    "                    df.iloc[i, -1] = series_name\n",
    "        \n",
    "        df[\"cha_kabu_num_Series_bigram\"] = df[\"cha_kabu_num_Series_bigram\"] / df.groupby('Series_Name_bigram')['Platform'].transform('nunique')\n",
    "        df[\"cha_kabu_num_Series_trigram\"] = df[\"cha_kabu_num_Series_trigram\"] / df.groupby('Series_Name_trigram')['Platform'].transform('nunique')\n",
    "        _groupby = df.groupby('Series_Name_bigram')\n",
    "        df['cha_kabu_Series_bigram_diff_years'] = _groupby['Year_of_Release'].transform('max') - _groupby['Year_of_Release'].transform('min')\n",
    "        df['cha_kabu_Series_bigram_elapsed_years'] = df['Year_of_Release'] - _groupby['Year_of_Release'].transform('min')\n",
    "        _groupby = df.groupby('Series_Name_trigram')\n",
    "        df['cha_kabu_Series_trigram_diff_years'] = _groupby['Year_of_Release'].transform('max') - _groupby['Year_of_Release'].transform('min')\n",
    "        df['cha_kabu_Series_trigram_elapsed_years'] = df['Year_of_Release'] - _groupby['Year_of_Release'].transform('min')\n",
    "        \n",
    "        self.groups = df['Series_Name_bigram'].values\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def execute(self, df: pd.DataFrame, is_train: bool=True, exec_target_encoding=False) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 1st place solution https://www.guruguru.science/competitions/13/discussions/343f21a0-948a-4a73-8899-e37bf25abf9c/\n",
    "        df_idx = df.index\n",
    "        df['n'] = 1\n",
    "        df = df.sort_values(['Genre', 'Year_of_Release'], ascending=False)\n",
    "        df_idx = df.index\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['Genre_serial_num_per'] = df.groupby(['Genre', 'Year_of_Release'])['n'].transform('cumsum')\n",
    "        summary = df.groupby(['Genre', 'Year_of_Release'])['n'].transform('sum')\n",
    "        df['Genre_serial_num_per'] = df['Genre_serial_num_per'] / summary\n",
    "        df.index = df_idx\n",
    "        df = df.sort_index()\n",
    "        df = df.sort_values(['Name', 'Year_of_Release'], ascending=False)\n",
    "        df_idx = df.index\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['Name_serial_num_per'] = df.groupby(['Name', 'Year_of_Release'])['n'].transform('cumsum')\n",
    "        summary = df.groupby(['Name', 'Year_of_Release'])['n'].transform('sum')\n",
    "        df['Name_serial_num_per'] = df['Genre_serial_num_per'] / summary\n",
    "\n",
    "        df = df.drop('n', axis=1)\n",
    "        df.index = df_idx\n",
    "        df = df.sort_index()\n",
    "        df['User_Score_is_tbd'] = (df['User_Score'] == 'tbd').astype(int)\n",
    "        df['User_Score'] = df['User_Score'].apply(lambda x: x if x!='tbd' else np.nan).astype(float)\n",
    "        # User_ScoreとCritic Scoreの差分\n",
    "        df['diff_User_Critic_Score'] = df['Critic_Score'] - (df['User_Score'] * 10)\n",
    "        # User_Score, Critic Scoreを相互にfillnaする\n",
    "        df['Critic_Score'] = df['Critic_Score'].fillna(df['User_Score'] * 10)\n",
    "        df['User_Score'] = df['User_Score'].fillna(df['Critic_Score'] / 10)\n",
    "        df['same_pub_dev'] = (df['Publisher'] == df['Developer']).astype(int)\n",
    "        df['multi_platform_count'] = df.groupby('Name')['Platform'].transform('nunique')\n",
    "        \n",
    "        # UnknownをDeveloperでfillnaする\n",
    "        df['Publisher'] = df['Publisher'].apply(lambda x: np.nan if x=='Unknown' else x).fillna(df['Developer'])\n",
    "        \n",
    "        # cat concat\n",
    "        self.concat_cols = []\n",
    "        for left, right in [\n",
    "            ('Genre', 'Platform'),\n",
    "            ('Genre', 'Rating'),\n",
    "            ('Genre', 'Bin_Year'),\n",
    "            ('Platform', 'Rating'),\n",
    "            ('Platform', 'Bin_Year'),\n",
    "            ('Rating', 'Bin_Year')\n",
    "        ]:\n",
    "            df[f'{left}_{right}'] = df[left].astype(str).fillna('nan_value') + '_' + df[right].astype(str).fillna('nan_value')\n",
    "            df[f'{left}_{right}'] = df[f'{left}_{right}'].apply(lambda x: np.nan if x=='nan_value' else x)\n",
    "            self.concat_cols.append(f'{left}_{right}')\n",
    "        \n",
    "        if is_train:\n",
    "            self.groups = df['Publisher'].values\n",
    "        \n",
    "        if exec_target_encoding:\n",
    "            # target encoding\n",
    "            encode_cols = ['Platform', 'Genre', 'Developer', 'Rating', 'Bin_Year'] + self.concat_cols\n",
    "            for encode_col in tqdm(encode_cols):\n",
    "                if is_train:\n",
    "                    df = self.target_encoding_train(df, df['Global_Sales'].copy(), encode_col, replace=False, target_name='Global_Sales')\n",
    "                    df = self.target_encoding_train(df, df['NA_Sales'].copy(), encode_col, replace=False, target_name='NA_Sales')\n",
    "                    df = self.target_encoding_train(df, df['EU_Sales'].copy(), encode_col, replace=False, target_name='EU_Sales')\n",
    "                    df = self.target_encoding_train(df, df['JP_Sales'].copy(), encode_col, replace=False, target_name='JP_Sales')\n",
    "                    df = self.target_encoding_train(df, df['Other_Sales'].copy(), encode_col, replace=False, target_name='other_Sales')\n",
    "                else:\n",
    "                    df = self.target_encoding_test(df, encode_col, replace=False, target_name='Global_Sales')\n",
    "                    df = self.target_encoding_test(df, encode_col, replace=False, target_name='NA_Sales')\n",
    "                    df = self.target_encoding_test(df, encode_col, replace=False, target_name='EU_Sales')\n",
    "                    df = self.target_encoding_test(df, encode_col, replace=False, target_name='JP_Sales')\n",
    "                    df = self.target_encoding_test(df, encode_col, replace=False, target_name='other_Sales')\n",
    "\n",
    "        \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def drop_cols(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # drop cols\n",
    "        DROP_COLS = ['Publisher', 'Name',\n",
    "                     'Name_Head_1', 'Name_Head_2', 'Name_Head_3', 'Developer',\n",
    "                    'Series_Name_bigram', 'Series_Name_trigram'\n",
    "                    ]\n",
    "        df = df.drop(DROP_COLS, axis=1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def parse_Name_head(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df['Name_Head_1'] = df['Name'].astype(str).apply(lambda x: x.split()[0])\n",
    "        df['Name_Head_2'] = df['Name'].astype(str).apply(\n",
    "                lambda x: x.split()[0] + ' ' +  x.split()[1] if len(x.split()) > 1 else x.split()[0])\n",
    "        df['Name_Head_3'] = df['Name'].astype(str).apply(\n",
    "                lambda x: x.split()[0] + ' ' +  x.split()[1] + ' ' +  x.split()[2] if len(x.split()) > 2 else x.split()[0])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:37:53.866468Z",
     "start_time": "2020-12-14T12:37:30.187835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd5267f99444f879a71fb64e53fc079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0793ddab474ebc8175ab844c2968d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1355c14a674e8bb997f4e44cd215d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5571f230402d401bb658814ce0bcd217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9f2d275e7f4a3ebbd39b05364c4f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a4ba54b3754f6c932aee77d5832f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98ab49799a74f03b550e4b28147aae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b2d73cc1fc4fcfa16399454304fd32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f1149fe5d24a8a8062543f3d90056a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64af346aa1994a8d9b65328ef59dabf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e87257bd2a4e31aa7e1f81f1279c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8d40ce36454161bdd0df54db07f33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4e31b698e14604bd4766a778dc85b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24548535799441d5b25d10de584b5233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d288c65c9341c9a02a7550bc144b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e595010369ce491a9edb95c56ebdbdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "proc = Preprocessing()\n",
    "len_train = train.shape[0]\n",
    "train = proc.parse_Name_head(train)\n",
    "test = proc.parse_Name_head(test)\n",
    "\n",
    "train_test = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "train_test['Bin_Year'] = pd.cut(train_test['Year_of_Release'], bins=10, labels=False)\n",
    "train = train_test.iloc[:len_train, :]\n",
    "test = train_test.iloc[len_train:, :].reset_index(drop=True)\n",
    "\n",
    "train = proc.execute(train, exec_target_encoding=True)\n",
    "test = proc.execute(test, is_train=False, exec_target_encoding=True)\n",
    "\n",
    "# Developerはtrainとtestどっちにも存在するやつだけteすることにする\n",
    "for objective in ['Global_Sales', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'other_Sales']:\n",
    "    for i, both_exists in tqdm(enumerate(train['Developer'].isin(both_exists_developers))):\n",
    "        if both_exists:\n",
    "            pass\n",
    "        else:\n",
    "            train.loc[i, f'te_{objective}_Developer'] = np.nan\n",
    "    \n",
    "    for i, both_exists in tqdm(enumerate(test['Developer'].isin(both_exists_developers))):\n",
    "        if both_exists:\n",
    "            pass\n",
    "        else:\n",
    "            test.loc[i, f'te_{objective}_Developer'] = np.nan\n",
    "\n",
    "train_test = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "train_test = proc.groupby_aggregation(train_test)\n",
    "train = train_test.iloc[:len_train, :]\n",
    "test = train_test.iloc[len_train:, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:37:53.874417Z",
     "start_time": "2020-12-14T12:37:53.867444Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_lgb(X_train, y_train, X_test, kf, seed=0):\n",
    "    oof = np.zeros(X_train.shape[0])\n",
    "    y_pred = np.zeros(X_test.shape[0])\n",
    "    models = []\n",
    "        \n",
    "    for i, (train_index, valid_index) in enumerate(kf):\n",
    "        print(f'Start {i+1} fold')\n",
    "        print('-' * 20)\n",
    "        X_tr, y_tr = X_train.iloc[train_index, :], y_train.iloc[train_index]\n",
    "        X_val, y_val = X_train.iloc[valid_index, :], y_train.iloc[valid_index]\n",
    "        X_tes = X_test.copy()\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_tr, y_tr)\n",
    "        lgb_valid = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "        lgb_params = {\n",
    "            'objective': 'rmse',\n",
    "            'metric': 'rmse',\n",
    "            'max_depth': 3,\n",
    "            'num_leaves': 2 ** 8,\n",
    "            'learning_rate': 0.01,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'feature_fraction': 0.1,\n",
    "            'random_state': seed,\n",
    "            'verbosity': -1\n",
    "            }\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            lgb_train,\n",
    "            valid_sets=(lgb_train, lgb_valid),\n",
    "            num_boost_round=100000,\n",
    "            early_stopping_rounds=1000,\n",
    "            verbose_eval=1000\n",
    "        )\n",
    "        oof[valid_index] = model.predict(X_val)\n",
    "        y_pred += model.predict(X_tes) / 5\n",
    "        models.append(model)\n",
    "    \n",
    "    return oof, y_pred, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:37:53.917004Z",
     "start_time": "2020-12-14T12:37:53.875380Z"
    }
   },
   "outputs": [],
   "source": [
    "train = proc.drop_cols(train)\n",
    "test = proc.drop_cols(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year_of_Releaseをfillnaする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:37:53.925469Z",
     "start_time": "2020-12-14T12:37:53.918706Z"
    }
   },
   "outputs": [],
   "source": [
    "def fillna_prediction(train, test, colname, inplace=True):\n",
    "    train[f'isna_{colname}'] = train[colname].isna().astype(int)\n",
    "    test[f'isna_{colname}'] = test[colname].isna().astype(int)\n",
    "    train_test = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "    X_train = (\n",
    "        train_test[train_test[colname].notna()]\n",
    "            .drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis=1)\n",
    "    )\n",
    "    X_tr_idx = X_train.index\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_train = X_train[colname].copy()\n",
    "    X_train = X_train.drop(colname, axis=1)\n",
    "    X_test = (\n",
    "        train_test[train_test[colname].isna()]\n",
    "            .drop([colname, 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis=1)\n",
    "    )\n",
    "    X_tes_idx = X_test.index\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "    CAT_FEATS = ['Platform', 'Genre', 'Rating'] + proc.concat_cols\n",
    "    X_train.loc[:, CAT_FEATS] = X_train[CAT_FEATS].astype('category')\n",
    "    X_test.loc[:, CAT_FEATS] = X_test[CAT_FEATS].astype('category')\n",
    "    oof, y_pred, models = train_lgb(X_train, y_train, X_test, KFold(n_splits=5, shuffle=True, random_state=0).split(X_train))\n",
    "    if inplace:\n",
    "        X_train = pd.concat([X_train, y_train], axis=1)\n",
    "        X_test = pd.concat([X_test, pd.Series(y_pred, name=colname)], axis=1)\n",
    "        X_train.index = X_tr_idx\n",
    "        X_test.index = X_tes_idx\n",
    "        train_test2 = pd.concat([X_train, X_test], axis=0).sort_index()\n",
    "        print(X_train.shape, X_test.shape, train_test.shape, train_test2.shape)\n",
    "        train_test2 = pd.concat([train_test2, train_test[['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']]], axis=1)\n",
    "        train = train_test2.iloc[:len(train), :]\n",
    "        test = train_test2.iloc[len(train):, :]\n",
    "        return train, test\n",
    "    else:\n",
    "        train_test2 = pd.concat([train_test, pd.Series(np.concatenate((oof, y_pred)), name=f'{colname}_pred')], axis=1)\n",
    "        train = train_test2.iloc[:len(train), :]\n",
    "        test = train_test2.iloc[len(train):, :]\n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:40:32.791959Z",
     "start_time": "2020-12-14T12:37:53.926923Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 1 fold\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning:\n",
      "\n",
      "Overriding the parameters from Reference Dataset.\n",
      "\n",
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning:\n",
      "\n",
      "categorical_column in param dict is overridden.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's rmse: 0.134829\tvalid_1's rmse: 0.280695\n",
      "[2000]\ttraining's rmse: 0.0871685\tvalid_1's rmse: 0.228525\n",
      "[3000]\ttraining's rmse: 0.0624867\tvalid_1's rmse: 0.202075\n",
      "[4000]\ttraining's rmse: 0.0471461\tvalid_1's rmse: 0.186555\n",
      "[5000]\ttraining's rmse: 0.037268\tvalid_1's rmse: 0.176773\n",
      "[6000]\ttraining's rmse: 0.0309548\tvalid_1's rmse: 0.170628\n",
      "[7000]\ttraining's rmse: 0.0267687\tvalid_1's rmse: 0.166854\n",
      "[8000]\ttraining's rmse: 0.0238698\tvalid_1's rmse: 0.164654\n",
      "[9000]\ttraining's rmse: 0.0215024\tvalid_1's rmse: 0.163215\n",
      "[10000]\ttraining's rmse: 0.0195147\tvalid_1's rmse: 0.162115\n",
      "[11000]\ttraining's rmse: 0.0177494\tvalid_1's rmse: 0.16116\n",
      "[12000]\ttraining's rmse: 0.0163008\tvalid_1's rmse: 0.160518\n",
      "[13000]\ttraining's rmse: 0.0150833\tvalid_1's rmse: 0.160014\n",
      "[14000]\ttraining's rmse: 0.0140557\tvalid_1's rmse: 0.159624\n",
      "[15000]\ttraining's rmse: 0.0131231\tvalid_1's rmse: 0.159371\n",
      "[16000]\ttraining's rmse: 0.0123298\tvalid_1's rmse: 0.159135\n",
      "[17000]\ttraining's rmse: 0.0116291\tvalid_1's rmse: 0.158973\n",
      "[18000]\ttraining's rmse: 0.0110313\tvalid_1's rmse: 0.158769\n",
      "[19000]\ttraining's rmse: 0.0104657\tvalid_1's rmse: 0.158648\n",
      "[20000]\ttraining's rmse: 0.00994952\tvalid_1's rmse: 0.158606\n",
      "[21000]\ttraining's rmse: 0.00950069\tvalid_1's rmse: 0.158531\n",
      "[22000]\ttraining's rmse: 0.00907831\tvalid_1's rmse: 0.158453\n",
      "[23000]\ttraining's rmse: 0.00870478\tvalid_1's rmse: 0.158381\n",
      "[24000]\ttraining's rmse: 0.00834967\tvalid_1's rmse: 0.158317\n",
      "[25000]\ttraining's rmse: 0.00802273\tvalid_1's rmse: 0.158245\n",
      "[26000]\ttraining's rmse: 0.00771342\tvalid_1's rmse: 0.158162\n",
      "[27000]\ttraining's rmse: 0.00744005\tvalid_1's rmse: 0.158117\n",
      "[28000]\ttraining's rmse: 0.00718043\tvalid_1's rmse: 0.15811\n",
      "[29000]\ttraining's rmse: 0.00694198\tvalid_1's rmse: 0.158074\n",
      "[30000]\ttraining's rmse: 0.0067085\tvalid_1's rmse: 0.15804\n",
      "[31000]\ttraining's rmse: 0.00649945\tvalid_1's rmse: 0.158015\n",
      "[32000]\ttraining's rmse: 0.00628891\tvalid_1's rmse: 0.157972\n",
      "[33000]\ttraining's rmse: 0.00609712\tvalid_1's rmse: 0.157941\n",
      "[34000]\ttraining's rmse: 0.00591705\tvalid_1's rmse: 0.157916\n",
      "[35000]\ttraining's rmse: 0.00574329\tvalid_1's rmse: 0.157882\n",
      "[36000]\ttraining's rmse: 0.00559023\tvalid_1's rmse: 0.157867\n",
      "[37000]\ttraining's rmse: 0.00543453\tvalid_1's rmse: 0.157842\n",
      "[38000]\ttraining's rmse: 0.00527777\tvalid_1's rmse: 0.15783\n",
      "[39000]\ttraining's rmse: 0.00513002\tvalid_1's rmse: 0.157819\n",
      "[40000]\ttraining's rmse: 0.00500293\tvalid_1's rmse: 0.15781\n",
      "[41000]\ttraining's rmse: 0.00487267\tvalid_1's rmse: 0.157805\n",
      "[42000]\ttraining's rmse: 0.00474231\tvalid_1's rmse: 0.15778\n",
      "[43000]\ttraining's rmse: 0.00461859\tvalid_1's rmse: 0.157768\n",
      "[44000]\ttraining's rmse: 0.0045048\tvalid_1's rmse: 0.157754\n",
      "[45000]\ttraining's rmse: 0.00439213\tvalid_1's rmse: 0.157754\n",
      "[46000]\ttraining's rmse: 0.00428783\tvalid_1's rmse: 0.157748\n",
      "[47000]\ttraining's rmse: 0.00419522\tvalid_1's rmse: 0.157747\n",
      "Early stopping, best iteration is:\n",
      "[46396]\ttraining's rmse: 0.00424972\tvalid_1's rmse: 0.157741\n",
      "Start 2 fold\n",
      "--------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's rmse: 0.141984\tvalid_1's rmse: 0.165122\n",
      "[2000]\ttraining's rmse: 0.0800187\tvalid_1's rmse: 0.114927\n",
      "[3000]\ttraining's rmse: 0.0557376\tvalid_1's rmse: 0.0977051\n",
      "[4000]\ttraining's rmse: 0.0431982\tvalid_1's rmse: 0.0900437\n",
      "[5000]\ttraining's rmse: 0.0353951\tvalid_1's rmse: 0.0859326\n",
      "[6000]\ttraining's rmse: 0.029624\tvalid_1's rmse: 0.0836625\n",
      "[7000]\ttraining's rmse: 0.0254713\tvalid_1's rmse: 0.0818923\n",
      "[8000]\ttraining's rmse: 0.0225033\tvalid_1's rmse: 0.0808823\n",
      "[9000]\ttraining's rmse: 0.02013\tvalid_1's rmse: 0.0804003\n",
      "[10000]\ttraining's rmse: 0.0182475\tvalid_1's rmse: 0.0800593\n",
      "[11000]\ttraining's rmse: 0.0166259\tvalid_1's rmse: 0.0799302\n",
      "[12000]\ttraining's rmse: 0.015245\tvalid_1's rmse: 0.0796665\n",
      "[13000]\ttraining's rmse: 0.0141852\tvalid_1's rmse: 0.0795377\n",
      "[14000]\ttraining's rmse: 0.0132957\tvalid_1's rmse: 0.0794007\n",
      "[15000]\ttraining's rmse: 0.0125319\tvalid_1's rmse: 0.0792912\n",
      "[16000]\ttraining's rmse: 0.011823\tvalid_1's rmse: 0.0791241\n",
      "[17000]\ttraining's rmse: 0.0112263\tvalid_1's rmse: 0.078962\n",
      "[18000]\ttraining's rmse: 0.0106877\tvalid_1's rmse: 0.0788738\n",
      "[19000]\ttraining's rmse: 0.0102034\tvalid_1's rmse: 0.0788382\n",
      "[20000]\ttraining's rmse: 0.00974433\tvalid_1's rmse: 0.0788002\n",
      "[21000]\ttraining's rmse: 0.00933649\tvalid_1's rmse: 0.0787418\n",
      "[22000]\ttraining's rmse: 0.00892856\tvalid_1's rmse: 0.0787072\n",
      "[23000]\ttraining's rmse: 0.00859684\tvalid_1's rmse: 0.0786587\n",
      "[24000]\ttraining's rmse: 0.00828462\tvalid_1's rmse: 0.0786064\n",
      "[25000]\ttraining's rmse: 0.00799213\tvalid_1's rmse: 0.0785839\n",
      "[26000]\ttraining's rmse: 0.00772863\tvalid_1's rmse: 0.0785467\n",
      "[27000]\ttraining's rmse: 0.00746673\tvalid_1's rmse: 0.0785017\n",
      "[28000]\ttraining's rmse: 0.00724555\tvalid_1's rmse: 0.0784704\n",
      "[29000]\ttraining's rmse: 0.00702558\tvalid_1's rmse: 0.0784447\n",
      "[30000]\ttraining's rmse: 0.00681687\tvalid_1's rmse: 0.0784234\n",
      "[31000]\ttraining's rmse: 0.00662638\tvalid_1's rmse: 0.0784052\n",
      "[32000]\ttraining's rmse: 0.00643852\tvalid_1's rmse: 0.0783992\n",
      "[33000]\ttraining's rmse: 0.00625272\tvalid_1's rmse: 0.0783924\n",
      "[34000]\ttraining's rmse: 0.00608065\tvalid_1's rmse: 0.0783928\n",
      "[35000]\ttraining's rmse: 0.00592311\tvalid_1's rmse: 0.0783691\n",
      "[36000]\ttraining's rmse: 0.00577909\tvalid_1's rmse: 0.0783679\n",
      "[37000]\ttraining's rmse: 0.00562864\tvalid_1's rmse: 0.0783537\n",
      "Early stopping, best iteration is:\n",
      "[36879]\ttraining's rmse: 0.00564745\tvalid_1's rmse: 0.0783499\n",
      "Start 3 fold\n",
      "--------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's rmse: 0.13815\tvalid_1's rmse: 0.132719\n",
      "[2000]\ttraining's rmse: 0.0768281\tvalid_1's rmse: 0.0966024\n",
      "[3000]\ttraining's rmse: 0.053518\tvalid_1's rmse: 0.0844299\n",
      "[4000]\ttraining's rmse: 0.0417335\tvalid_1's rmse: 0.0792262\n",
      "[5000]\ttraining's rmse: 0.034313\tvalid_1's rmse: 0.076506\n",
      "[6000]\ttraining's rmse: 0.0290491\tvalid_1's rmse: 0.0749472\n",
      "[7000]\ttraining's rmse: 0.0250558\tvalid_1's rmse: 0.0735245\n",
      "[8000]\ttraining's rmse: 0.0222704\tvalid_1's rmse: 0.0727254\n",
      "[9000]\ttraining's rmse: 0.0199284\tvalid_1's rmse: 0.0720837\n",
      "[10000]\ttraining's rmse: 0.0181214\tvalid_1's rmse: 0.0716551\n",
      "[11000]\ttraining's rmse: 0.0165621\tvalid_1's rmse: 0.0712409\n",
      "[12000]\ttraining's rmse: 0.0152702\tvalid_1's rmse: 0.070991\n",
      "[13000]\ttraining's rmse: 0.014205\tvalid_1's rmse: 0.0707647\n",
      "[14000]\ttraining's rmse: 0.0133013\tvalid_1's rmse: 0.0706067\n",
      "[15000]\ttraining's rmse: 0.0124844\tvalid_1's rmse: 0.0705235\n",
      "[16000]\ttraining's rmse: 0.0117616\tvalid_1's rmse: 0.070355\n",
      "[17000]\ttraining's rmse: 0.0111464\tvalid_1's rmse: 0.0702593\n",
      "[18000]\ttraining's rmse: 0.0105951\tvalid_1's rmse: 0.0701264\n",
      "[19000]\ttraining's rmse: 0.0101066\tvalid_1's rmse: 0.0700679\n",
      "[20000]\ttraining's rmse: 0.00965887\tvalid_1's rmse: 0.0699816\n",
      "[21000]\ttraining's rmse: 0.00926678\tvalid_1's rmse: 0.0699227\n",
      "[22000]\ttraining's rmse: 0.0089236\tvalid_1's rmse: 0.0699081\n",
      "Early stopping, best iteration is:\n",
      "[21357]\ttraining's rmse: 0.00913826\tvalid_1's rmse: 0.0698992\n",
      "Start 4 fold\n",
      "--------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's rmse: 0.145118\tvalid_1's rmse: 0.155854\n",
      "[2000]\ttraining's rmse: 0.084564\tvalid_1's rmse: 0.100798\n",
      "[3000]\ttraining's rmse: 0.0580656\tvalid_1's rmse: 0.0788001\n",
      "[4000]\ttraining's rmse: 0.0451234\tvalid_1's rmse: 0.0687547\n",
      "[5000]\ttraining's rmse: 0.0371286\tvalid_1's rmse: 0.0637974\n",
      "[6000]\ttraining's rmse: 0.0316105\tvalid_1's rmse: 0.0603047\n",
      "[7000]\ttraining's rmse: 0.0275656\tvalid_1's rmse: 0.0577419\n",
      "[8000]\ttraining's rmse: 0.0244536\tvalid_1's rmse: 0.0559483\n",
      "[9000]\ttraining's rmse: 0.0220347\tvalid_1's rmse: 0.0545778\n",
      "[10000]\ttraining's rmse: 0.0200621\tvalid_1's rmse: 0.0535474\n",
      "[11000]\ttraining's rmse: 0.0183929\tvalid_1's rmse: 0.0526915\n",
      "[12000]\ttraining's rmse: 0.0169684\tvalid_1's rmse: 0.0519109\n",
      "[13000]\ttraining's rmse: 0.0157536\tvalid_1's rmse: 0.0513485\n",
      "[14000]\ttraining's rmse: 0.0147231\tvalid_1's rmse: 0.050744\n",
      "[15000]\ttraining's rmse: 0.0137998\tvalid_1's rmse: 0.0502597\n",
      "[16000]\ttraining's rmse: 0.012963\tvalid_1's rmse: 0.0498614\n",
      "[17000]\ttraining's rmse: 0.012233\tvalid_1's rmse: 0.0495131\n",
      "[18000]\ttraining's rmse: 0.0115812\tvalid_1's rmse: 0.049245\n",
      "[19000]\ttraining's rmse: 0.0109964\tvalid_1's rmse: 0.0489947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20000]\ttraining's rmse: 0.0104391\tvalid_1's rmse: 0.04884\n",
      "[21000]\ttraining's rmse: 0.00998375\tvalid_1's rmse: 0.048651\n",
      "[22000]\ttraining's rmse: 0.00952699\tvalid_1's rmse: 0.0484888\n",
      "[23000]\ttraining's rmse: 0.00912804\tvalid_1's rmse: 0.048366\n",
      "[24000]\ttraining's rmse: 0.00875863\tvalid_1's rmse: 0.0482604\n",
      "[25000]\ttraining's rmse: 0.00840826\tvalid_1's rmse: 0.0481879\n",
      "[26000]\ttraining's rmse: 0.0081023\tvalid_1's rmse: 0.0480695\n",
      "[27000]\ttraining's rmse: 0.00780117\tvalid_1's rmse: 0.047972\n",
      "[28000]\ttraining's rmse: 0.00753867\tvalid_1's rmse: 0.0478821\n",
      "[29000]\ttraining's rmse: 0.00729216\tvalid_1's rmse: 0.0478148\n",
      "[30000]\ttraining's rmse: 0.00706213\tvalid_1's rmse: 0.0477272\n",
      "[31000]\ttraining's rmse: 0.00684252\tvalid_1's rmse: 0.0476594\n",
      "[32000]\ttraining's rmse: 0.00663579\tvalid_1's rmse: 0.0476023\n",
      "[33000]\ttraining's rmse: 0.00644045\tvalid_1's rmse: 0.047546\n",
      "[34000]\ttraining's rmse: 0.00626721\tvalid_1's rmse: 0.0475073\n",
      "[35000]\ttraining's rmse: 0.00609491\tvalid_1's rmse: 0.0474696\n",
      "[36000]\ttraining's rmse: 0.00593209\tvalid_1's rmse: 0.0474193\n",
      "[37000]\ttraining's rmse: 0.00577718\tvalid_1's rmse: 0.0473875\n",
      "[38000]\ttraining's rmse: 0.00562844\tvalid_1's rmse: 0.0473462\n",
      "[39000]\ttraining's rmse: 0.00548752\tvalid_1's rmse: 0.0473106\n",
      "[40000]\ttraining's rmse: 0.00535991\tvalid_1's rmse: 0.0472791\n",
      "[41000]\ttraining's rmse: 0.0052285\tvalid_1's rmse: 0.0472519\n",
      "[42000]\ttraining's rmse: 0.00510314\tvalid_1's rmse: 0.0472298\n",
      "[43000]\ttraining's rmse: 0.00498169\tvalid_1's rmse: 0.0471953\n",
      "[44000]\ttraining's rmse: 0.00486443\tvalid_1's rmse: 0.0471788\n",
      "[45000]\ttraining's rmse: 0.00475578\tvalid_1's rmse: 0.0471654\n",
      "[46000]\ttraining's rmse: 0.00464606\tvalid_1's rmse: 0.0471416\n",
      "[47000]\ttraining's rmse: 0.0045457\tvalid_1's rmse: 0.0471228\n",
      "[48000]\ttraining's rmse: 0.00444495\tvalid_1's rmse: 0.0470993\n",
      "[49000]\ttraining's rmse: 0.00435079\tvalid_1's rmse: 0.0470852\n",
      "[50000]\ttraining's rmse: 0.00426085\tvalid_1's rmse: 0.0470672\n",
      "[51000]\ttraining's rmse: 0.00417032\tvalid_1's rmse: 0.0470518\n",
      "[52000]\ttraining's rmse: 0.00408664\tvalid_1's rmse: 0.0470375\n",
      "[53000]\ttraining's rmse: 0.00399931\tvalid_1's rmse: 0.0470243\n",
      "[54000]\ttraining's rmse: 0.00392087\tvalid_1's rmse: 0.0470183\n",
      "[55000]\ttraining's rmse: 0.00384315\tvalid_1's rmse: 0.0470039\n",
      "[56000]\ttraining's rmse: 0.00376527\tvalid_1's rmse: 0.0469932\n",
      "[57000]\ttraining's rmse: 0.00369268\tvalid_1's rmse: 0.0469919\n",
      "[58000]\ttraining's rmse: 0.00362522\tvalid_1's rmse: 0.0469863\n",
      "[59000]\ttraining's rmse: 0.00355934\tvalid_1's rmse: 0.0469794\n",
      "[60000]\ttraining's rmse: 0.003495\tvalid_1's rmse: 0.0469764\n",
      "[61000]\ttraining's rmse: 0.00343209\tvalid_1's rmse: 0.0469698\n",
      "[62000]\ttraining's rmse: 0.00337184\tvalid_1's rmse: 0.0469639\n",
      "[63000]\ttraining's rmse: 0.00331596\tvalid_1's rmse: 0.0469609\n",
      "[64000]\ttraining's rmse: 0.00325933\tvalid_1's rmse: 0.046952\n",
      "[65000]\ttraining's rmse: 0.00320491\tvalid_1's rmse: 0.0469506\n",
      "[66000]\ttraining's rmse: 0.00315062\tvalid_1's rmse: 0.0469457\n",
      "[67000]\ttraining's rmse: 0.00309848\tvalid_1's rmse: 0.0469387\n",
      "[68000]\ttraining's rmse: 0.00305039\tvalid_1's rmse: 0.0469343\n",
      "[69000]\ttraining's rmse: 0.00300224\tvalid_1's rmse: 0.046928\n",
      "[70000]\ttraining's rmse: 0.00295239\tvalid_1's rmse: 0.0469215\n",
      "[71000]\ttraining's rmse: 0.00290705\tvalid_1's rmse: 0.0469194\n",
      "[72000]\ttraining's rmse: 0.00286022\tvalid_1's rmse: 0.0469137\n",
      "[73000]\ttraining's rmse: 0.0028158\tvalid_1's rmse: 0.0469079\n",
      "[74000]\ttraining's rmse: 0.00277477\tvalid_1's rmse: 0.0469046\n",
      "[75000]\ttraining's rmse: 0.0027302\tvalid_1's rmse: 0.046899\n",
      "[76000]\ttraining's rmse: 0.00268805\tvalid_1's rmse: 0.0468969\n",
      "[77000]\ttraining's rmse: 0.00264598\tvalid_1's rmse: 0.0468917\n",
      "[78000]\ttraining's rmse: 0.00260811\tvalid_1's rmse: 0.0468913\n",
      "[79000]\ttraining's rmse: 0.00257251\tvalid_1's rmse: 0.0468856\n",
      "[80000]\ttraining's rmse: 0.00253522\tvalid_1's rmse: 0.0468817\n",
      "[81000]\ttraining's rmse: 0.00250196\tvalid_1's rmse: 0.0468793\n",
      "Early stopping, best iteration is:\n",
      "[80787]\ttraining's rmse: 0.00250913\tvalid_1's rmse: 0.0468776\n",
      "Start 5 fold\n",
      "--------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's rmse: 0.138857\tvalid_1's rmse: 0.109661\n",
      "[2000]\ttraining's rmse: 0.0785254\tvalid_1's rmse: 0.0840103\n",
      "[3000]\ttraining's rmse: 0.0558325\tvalid_1's rmse: 0.0715115\n",
      "[4000]\ttraining's rmse: 0.0439123\tvalid_1's rmse: 0.0644991\n",
      "[5000]\ttraining's rmse: 0.0358582\tvalid_1's rmse: 0.060238\n",
      "[6000]\ttraining's rmse: 0.0299519\tvalid_1's rmse: 0.0576226\n",
      "[7000]\ttraining's rmse: 0.0259354\tvalid_1's rmse: 0.056039\n",
      "[8000]\ttraining's rmse: 0.0229103\tvalid_1's rmse: 0.0551463\n",
      "[9000]\ttraining's rmse: 0.0204988\tvalid_1's rmse: 0.0544067\n",
      "[10000]\ttraining's rmse: 0.0185666\tvalid_1's rmse: 0.0538156\n",
      "[11000]\ttraining's rmse: 0.016968\tvalid_1's rmse: 0.0530588\n",
      "[12000]\ttraining's rmse: 0.0155831\tvalid_1's rmse: 0.052503\n",
      "[13000]\ttraining's rmse: 0.0144745\tvalid_1's rmse: 0.0521788\n",
      "[14000]\ttraining's rmse: 0.0135134\tvalid_1's rmse: 0.0519563\n",
      "[15000]\ttraining's rmse: 0.0126599\tvalid_1's rmse: 0.0517605\n",
      "[16000]\ttraining's rmse: 0.0119321\tvalid_1's rmse: 0.051576\n",
      "[17000]\ttraining's rmse: 0.0112868\tvalid_1's rmse: 0.0513954\n",
      "[18000]\ttraining's rmse: 0.0106927\tvalid_1's rmse: 0.0512214\n",
      "[19000]\ttraining's rmse: 0.0101663\tvalid_1's rmse: 0.0511109\n",
      "[20000]\ttraining's rmse: 0.00966467\tvalid_1's rmse: 0.050982\n",
      "[21000]\ttraining's rmse: 0.00925035\tvalid_1's rmse: 0.0508781\n",
      "[22000]\ttraining's rmse: 0.00883377\tvalid_1's rmse: 0.0507875\n",
      "[23000]\ttraining's rmse: 0.00847699\tvalid_1's rmse: 0.0507391\n",
      "[24000]\ttraining's rmse: 0.00815472\tvalid_1's rmse: 0.0506509\n",
      "[25000]\ttraining's rmse: 0.00784428\tvalid_1's rmse: 0.0505914\n",
      "[26000]\ttraining's rmse: 0.0075653\tvalid_1's rmse: 0.0505377\n",
      "[27000]\ttraining's rmse: 0.00731079\tvalid_1's rmse: 0.0504972\n",
      "[28000]\ttraining's rmse: 0.00707979\tvalid_1's rmse: 0.0504274\n",
      "[29000]\ttraining's rmse: 0.00684963\tvalid_1's rmse: 0.0503853\n",
      "[30000]\ttraining's rmse: 0.0066417\tvalid_1's rmse: 0.0503381\n",
      "[31000]\ttraining's rmse: 0.00644052\tvalid_1's rmse: 0.0503058\n",
      "[32000]\ttraining's rmse: 0.00624609\tvalid_1's rmse: 0.0502793\n",
      "[33000]\ttraining's rmse: 0.00606767\tvalid_1's rmse: 0.0502412\n",
      "[34000]\ttraining's rmse: 0.00589301\tvalid_1's rmse: 0.0501892\n",
      "[35000]\ttraining's rmse: 0.0057325\tvalid_1's rmse: 0.0501602\n",
      "[36000]\ttraining's rmse: 0.00557553\tvalid_1's rmse: 0.0501157\n",
      "[37000]\ttraining's rmse: 0.00541752\tvalid_1's rmse: 0.0500851\n",
      "[38000]\ttraining's rmse: 0.00527925\tvalid_1's rmse: 0.0500587\n",
      "[39000]\ttraining's rmse: 0.00514831\tvalid_1's rmse: 0.0500272\n",
      "[40000]\ttraining's rmse: 0.0050181\tvalid_1's rmse: 0.050007\n",
      "[41000]\ttraining's rmse: 0.00489618\tvalid_1's rmse: 0.05\n",
      "[42000]\ttraining's rmse: 0.00478288\tvalid_1's rmse: 0.0499841\n",
      "[43000]\ttraining's rmse: 0.00467466\tvalid_1's rmse: 0.0499711\n",
      "[44000]\ttraining's rmse: 0.00456911\tvalid_1's rmse: 0.0499524\n",
      "[45000]\ttraining's rmse: 0.00446515\tvalid_1's rmse: 0.0499357\n",
      "[46000]\ttraining's rmse: 0.00437325\tvalid_1's rmse: 0.0499177\n",
      "[47000]\ttraining's rmse: 0.00428488\tvalid_1's rmse: 0.0499038\n",
      "[48000]\ttraining's rmse: 0.0041966\tvalid_1's rmse: 0.049898\n",
      "[49000]\ttraining's rmse: 0.00410961\tvalid_1's rmse: 0.0498799\n",
      "[50000]\ttraining's rmse: 0.00402095\tvalid_1's rmse: 0.0498755\n",
      "Early stopping, best iteration is:\n",
      "[49656]\ttraining's rmse: 0.00405047\tvalid_1's rmse: 0.0498729\n",
      "(15750, 642) (263, 642) (16013, 647) (16013, 642)\n"
     ]
    }
   ],
   "source": [
    "train, test = fillna_prediction(train, test, 'Year_of_Release')\n",
    "#train, test = fillna_prediction(train, test, 'User_Count', inplace=False)\n",
    "#train, test = fillna_prediction(train, test, 'Critic_Count', inplace=False)\n",
    "#train, test = fillna_prediction(train, test, 'User_Score', inplace=False)\n",
    "#train, test = fillna_prediction(train, test, 'Critic_Score', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:40:56.849997Z",
     "start_time": "2020-12-14T12:40:32.793104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0644056c83fb4694acb707ebbbed2ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb717b1a41648deae5e91590bb708f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3b2dfb79494af890819c9b868dda33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b50ba787c0411f8f47d4e502b63a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4dbe44f831406fadfa854e19e03342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84384275669a4ffb94c2b099efab7739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c82bc14ef5437a8594d23c35202a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559126fc5b2c41d28415dcd70d509aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b815d94ece4a6ca581b5393f31eed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23db25e9f26840398854ad8c887d0aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14a47a35de14ca08a80240aa3fc6d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64b70c54eba4b0fb769a714ca71d1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb931576272441678a40634821dbae57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9a12156df443f4913fa013a5736423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eccb6dd4144693b1f24af1868fa265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5eee81b294e4cbcaf20f435332b5c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_filled_year = train['Year_of_Release'].astype(int).values\n",
    "test_filled_year = test['Year_of_Release'].astype(int).values\n",
    "\n",
    "train, test, submit = read_data()\n",
    "# drop nintendo\n",
    "train = train[train['Publisher']!='Nintendo'].reset_index(drop=True)\n",
    "\n",
    "train['Year_of_Release'] = train_filled_year\n",
    "test['Year_of_Release'] = test_filled_year\n",
    "\n",
    "proc = Preprocessing()\n",
    "len_train = train.shape[0]\n",
    "train = proc.parse_Name_head(train)\n",
    "test = proc.parse_Name_head(test)\n",
    "\n",
    "train_test = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "train_test['Bin_Year'] = pd.cut(train_test['Year_of_Release'], bins=10, labels=False)\n",
    "train = train_test.iloc[:len_train, :]\n",
    "test = train_test.iloc[len_train:, :].reset_index(drop=True)\n",
    "\n",
    "train = proc.execute(train, exec_target_encoding=True)\n",
    "test = proc.execute(test, is_train=False, exec_target_encoding=True)\n",
    "\n",
    "# Developerはtrainとtestどっちにも存在するやつだけteすることにする\n",
    "for objective in ['Global_Sales', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'other_Sales']:\n",
    "    for i, both_exists in tqdm(enumerate(train['Developer'].isin(both_exists_developers))):\n",
    "        if both_exists:\n",
    "            pass\n",
    "        else:\n",
    "            train.loc[i, f'te_{objective}_Developer'] = np.nan\n",
    "    \n",
    "    for i, both_exists in tqdm(enumerate(test['Developer'].isin(both_exists_developers))):\n",
    "        if both_exists:\n",
    "            pass\n",
    "        else:\n",
    "            test.loc[i, f'te_{objective}_Developer'] = np.nan\n",
    "\n",
    "train_test = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "train_test = proc.groupby_aggregation(train_test)\n",
    "train = train_test.iloc[:len_train, :]\n",
    "test = train_test.iloc[len_train:, :].reset_index(drop=True)\n",
    "\n",
    "train = proc.drop_cols(train)\n",
    "test = proc.drop_cols(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:40:56.875110Z",
     "start_time": "2020-12-14T12:40:56.851092Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, val in enumerate(proc.groups):\n",
    "    if type(val) != str:\n",
    "        if np.isnan([val]):\n",
    "            proc.groups[i] = f'nan_val_{i}'\n",
    "\n",
    "proc.groups = proc.groups[:len(train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:40:57.034211Z",
     "start_time": "2020-12-14T12:40:56.876025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../output/features.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((train, test, proc.groups), '../output/features.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:40:57.091838Z",
     "start_time": "2020-12-14T12:40:57.035200Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test, _ = joblib.load('../output/features.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:40:57.356479Z",
     "start_time": "2020-12-14T12:40:57.092870Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis=1)\n",
    "y_train = np.log1p(train['Global_Sales'])\n",
    "X_test = test.drop(['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:40:57.386889Z",
     "start_time": "2020-12-14T12:40:57.357949Z"
    }
   },
   "outputs": [],
   "source": [
    "CAT_FEATS = ['Platform', 'Genre', 'Rating'] + proc.concat_cols\n",
    "X_train.loc[:, CAT_FEATS] = X_train[CAT_FEATS].astype('category')\n",
    "X_test.loc[:, CAT_FEATS] = X_test[CAT_FEATS].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T12:40:57.390454Z",
     "start_time": "2020-12-14T12:40:57.387852Z"
    }
   },
   "outputs": [],
   "source": [
    "stratified_y = pd.cut(y_train, 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-14T12:37:28.249Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 1 fold\n",
      "--------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning:\n",
      "\n",
      "Overriding the parameters from Reference Dataset.\n",
      "\n",
      "/home/nekoumei/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning:\n",
      "\n",
      "categorical_column in param dict is overridden.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 0.506283\tvalid_1's rmse: 0.576925\n",
      "[2000]\ttraining's rmse: 0.376549\tvalid_1's rmse: 0.480493\n",
      "[3000]\ttraining's rmse: 0.319123\tvalid_1's rmse: 0.44359\n",
      "[4000]\ttraining's rmse: 0.286741\tvalid_1's rmse: 0.426166\n",
      "[5000]\ttraining's rmse: 0.262648\tvalid_1's rmse: 0.413216\n",
      "[6000]\ttraining's rmse: 0.245355\tvalid_1's rmse: 0.406521\n",
      "[7000]\ttraining's rmse: 0.230619\tvalid_1's rmse: 0.400529\n",
      "[8000]\ttraining's rmse: 0.218753\tvalid_1's rmse: 0.396394\n",
      "[9000]\ttraining's rmse: 0.208041\tvalid_1's rmse: 0.393258\n",
      "[10000]\ttraining's rmse: 0.198357\tvalid_1's rmse: 0.390473\n",
      "[11000]\ttraining's rmse: 0.189683\tvalid_1's rmse: 0.388417\n",
      "[12000]\ttraining's rmse: 0.181938\tvalid_1's rmse: 0.386834\n",
      "[13000]\ttraining's rmse: 0.174635\tvalid_1's rmse: 0.385355\n",
      "[14000]\ttraining's rmse: 0.168128\tvalid_1's rmse: 0.383902\n",
      "[15000]\ttraining's rmse: 0.162093\tvalid_1's rmse: 0.382508\n",
      "[16000]\ttraining's rmse: 0.156534\tvalid_1's rmse: 0.381435\n",
      "[17000]\ttraining's rmse: 0.151543\tvalid_1's rmse: 0.380519\n",
      "[18000]\ttraining's rmse: 0.146547\tvalid_1's rmse: 0.379413\n",
      "[19000]\ttraining's rmse: 0.142004\tvalid_1's rmse: 0.378677\n",
      "[20000]\ttraining's rmse: 0.137747\tvalid_1's rmse: 0.377923\n",
      "[21000]\ttraining's rmse: 0.133601\tvalid_1's rmse: 0.377259\n",
      "[22000]\ttraining's rmse: 0.129839\tvalid_1's rmse: 0.376716\n",
      "[23000]\ttraining's rmse: 0.126167\tvalid_1's rmse: 0.376177\n",
      "[24000]\ttraining's rmse: 0.122775\tvalid_1's rmse: 0.375748\n",
      "[25000]\ttraining's rmse: 0.119548\tvalid_1's rmse: 0.375271\n",
      "[26000]\ttraining's rmse: 0.116521\tvalid_1's rmse: 0.374798\n",
      "[27000]\ttraining's rmse: 0.113702\tvalid_1's rmse: 0.374501\n",
      "[28000]\ttraining's rmse: 0.110794\tvalid_1's rmse: 0.374308\n",
      "[29000]\ttraining's rmse: 0.108188\tvalid_1's rmse: 0.374041\n",
      "[30000]\ttraining's rmse: 0.105632\tvalid_1's rmse: 0.373696\n",
      "[31000]\ttraining's rmse: 0.103321\tvalid_1's rmse: 0.373414\n",
      "[32000]\ttraining's rmse: 0.101172\tvalid_1's rmse: 0.373252\n",
      "[33000]\ttraining's rmse: 0.0987967\tvalid_1's rmse: 0.37303\n",
      "[34000]\ttraining's rmse: 0.096732\tvalid_1's rmse: 0.372802\n",
      "[35000]\ttraining's rmse: 0.0947152\tvalid_1's rmse: 0.372595\n",
      "[36000]\ttraining's rmse: 0.0926717\tvalid_1's rmse: 0.372466\n",
      "[37000]\ttraining's rmse: 0.0906414\tvalid_1's rmse: 0.372258\n",
      "[38000]\ttraining's rmse: 0.0888257\tvalid_1's rmse: 0.372199\n",
      "[39000]\ttraining's rmse: 0.0870904\tvalid_1's rmse: 0.372072\n",
      "[40000]\ttraining's rmse: 0.0853681\tvalid_1's rmse: 0.371979\n",
      "[41000]\ttraining's rmse: 0.0837299\tvalid_1's rmse: 0.371836\n",
      "[42000]\ttraining's rmse: 0.0821557\tvalid_1's rmse: 0.371715\n",
      "[43000]\ttraining's rmse: 0.0806589\tvalid_1's rmse: 0.371582\n",
      "[44000]\ttraining's rmse: 0.0790957\tvalid_1's rmse: 0.37138\n",
      "[45000]\ttraining's rmse: 0.0777347\tvalid_1's rmse: 0.371301\n",
      "[46000]\ttraining's rmse: 0.0764016\tvalid_1's rmse: 0.371152\n",
      "[47000]\ttraining's rmse: 0.0751878\tvalid_1's rmse: 0.371042\n",
      "[48000]\ttraining's rmse: 0.0739489\tvalid_1's rmse: 0.370958\n",
      "[49000]\ttraining's rmse: 0.0727203\tvalid_1's rmse: 0.370837\n",
      "[50000]\ttraining's rmse: 0.0715137\tvalid_1's rmse: 0.370782\n",
      "[51000]\ttraining's rmse: 0.0702301\tvalid_1's rmse: 0.370693\n",
      "Early stopping, best iteration is:\n",
      "[50566]\ttraining's rmse: 0.0707484\tvalid_1's rmse: 0.37068\n",
      "Start 2 fold\n",
      "--------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's rmse: 0.507912\tvalid_1's rmse: 0.585382\n",
      "[2000]\ttraining's rmse: 0.380027\tvalid_1's rmse: 0.486404\n",
      "[3000]\ttraining's rmse: 0.322084\tvalid_1's rmse: 0.446554\n",
      "[4000]\ttraining's rmse: 0.289586\tvalid_1's rmse: 0.42687\n",
      "[5000]\ttraining's rmse: 0.265651\tvalid_1's rmse: 0.413198\n",
      "[6000]\ttraining's rmse: 0.24826\tvalid_1's rmse: 0.405214\n",
      "[7000]\ttraining's rmse: 0.233088\tvalid_1's rmse: 0.398249\n",
      "[8000]\ttraining's rmse: 0.22026\tvalid_1's rmse: 0.393327\n",
      "[9000]\ttraining's rmse: 0.209205\tvalid_1's rmse: 0.389547\n",
      "[10000]\ttraining's rmse: 0.199409\tvalid_1's rmse: 0.386574\n",
      "[11000]\ttraining's rmse: 0.190947\tvalid_1's rmse: 0.384254\n",
      "[12000]\ttraining's rmse: 0.1836\tvalid_1's rmse: 0.382145\n",
      "[13000]\ttraining's rmse: 0.176376\tvalid_1's rmse: 0.380181\n",
      "[14000]\ttraining's rmse: 0.169692\tvalid_1's rmse: 0.378586\n",
      "[15000]\ttraining's rmse: 0.163507\tvalid_1's rmse: 0.377243\n",
      "[16000]\ttraining's rmse: 0.157621\tvalid_1's rmse: 0.376043\n",
      "[17000]\ttraining's rmse: 0.152405\tvalid_1's rmse: 0.375321\n",
      "[18000]\ttraining's rmse: 0.147433\tvalid_1's rmse: 0.374404\n",
      "[19000]\ttraining's rmse: 0.143069\tvalid_1's rmse: 0.373652\n",
      "[20000]\ttraining's rmse: 0.138786\tvalid_1's rmse: 0.372943\n",
      "[21000]\ttraining's rmse: 0.134558\tvalid_1's rmse: 0.3722\n",
      "[22000]\ttraining's rmse: 0.130818\tvalid_1's rmse: 0.371644\n",
      "[23000]\ttraining's rmse: 0.127128\tvalid_1's rmse: 0.371128\n",
      "[24000]\ttraining's rmse: 0.123725\tvalid_1's rmse: 0.370718\n",
      "[25000]\ttraining's rmse: 0.120427\tvalid_1's rmse: 0.370278\n",
      "[26000]\ttraining's rmse: 0.117301\tvalid_1's rmse: 0.36988\n",
      "[27000]\ttraining's rmse: 0.114425\tvalid_1's rmse: 0.369589\n",
      "[28000]\ttraining's rmse: 0.111583\tvalid_1's rmse: 0.369273\n",
      "[29000]\ttraining's rmse: 0.108884\tvalid_1's rmse: 0.368983\n",
      "[30000]\ttraining's rmse: 0.106362\tvalid_1's rmse: 0.368851\n",
      "[31000]\ttraining's rmse: 0.10386\tvalid_1's rmse: 0.36861\n",
      "[32000]\ttraining's rmse: 0.101584\tvalid_1's rmse: 0.368546\n",
      "[33000]\ttraining's rmse: 0.0993146\tvalid_1's rmse: 0.368308\n",
      "[34000]\ttraining's rmse: 0.0972014\tvalid_1's rmse: 0.368103\n",
      "[35000]\ttraining's rmse: 0.0952578\tvalid_1's rmse: 0.367922\n",
      "[36000]\ttraining's rmse: 0.0932443\tvalid_1's rmse: 0.367741\n",
      "[37000]\ttraining's rmse: 0.0913148\tvalid_1's rmse: 0.367633\n",
      "[38000]\ttraining's rmse: 0.0895027\tvalid_1's rmse: 0.367529\n",
      "[39000]\ttraining's rmse: 0.0877156\tvalid_1's rmse: 0.367414\n",
      "[40000]\ttraining's rmse: 0.0860936\tvalid_1's rmse: 0.367179\n",
      "[41000]\ttraining's rmse: 0.0845929\tvalid_1's rmse: 0.366946\n",
      "[42000]\ttraining's rmse: 0.0830484\tvalid_1's rmse: 0.366838\n",
      "[43000]\ttraining's rmse: 0.0815851\tvalid_1's rmse: 0.366727\n",
      "[44000]\ttraining's rmse: 0.0800212\tvalid_1's rmse: 0.36665\n",
      "[45000]\ttraining's rmse: 0.0786484\tvalid_1's rmse: 0.366592\n",
      "[46000]\ttraining's rmse: 0.0773591\tvalid_1's rmse: 0.366516\n",
      "[47000]\ttraining's rmse: 0.0760123\tvalid_1's rmse: 0.366418\n",
      "[48000]\ttraining's rmse: 0.0747493\tvalid_1's rmse: 0.366327\n",
      "[49000]\ttraining's rmse: 0.0735016\tvalid_1's rmse: 0.366185\n",
      "[50000]\ttraining's rmse: 0.072299\tvalid_1's rmse: 0.366135\n",
      "Early stopping, best iteration is:\n",
      "[49950]\ttraining's rmse: 0.0723517\tvalid_1's rmse: 0.366114\n",
      "Start 3 fold\n",
      "--------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's rmse: 0.503063\tvalid_1's rmse: 0.609381\n",
      "[2000]\ttraining's rmse: 0.374708\tvalid_1's rmse: 0.516729\n",
      "[3000]\ttraining's rmse: 0.316776\tvalid_1's rmse: 0.480541\n",
      "[4000]\ttraining's rmse: 0.283573\tvalid_1's rmse: 0.462819\n",
      "[5000]\ttraining's rmse: 0.258867\tvalid_1's rmse: 0.450516\n",
      "[6000]\ttraining's rmse: 0.241201\tvalid_1's rmse: 0.443998\n",
      "[7000]\ttraining's rmse: 0.226445\tvalid_1's rmse: 0.438704\n",
      "[8000]\ttraining's rmse: 0.213919\tvalid_1's rmse: 0.43439\n",
      "[9000]\ttraining's rmse: 0.203193\tvalid_1's rmse: 0.431121\n",
      "[10000]\ttraining's rmse: 0.193422\tvalid_1's rmse: 0.42841\n",
      "[11000]\ttraining's rmse: 0.185182\tvalid_1's rmse: 0.426328\n",
      "[12000]\ttraining's rmse: 0.177492\tvalid_1's rmse: 0.42455\n",
      "[13000]\ttraining's rmse: 0.170519\tvalid_1's rmse: 0.423075\n",
      "[14000]\ttraining's rmse: 0.16419\tvalid_1's rmse: 0.421794\n",
      "[15000]\ttraining's rmse: 0.15837\tvalid_1's rmse: 0.420614\n",
      "[16000]\ttraining's rmse: 0.153001\tvalid_1's rmse: 0.419548\n",
      "[17000]\ttraining's rmse: 0.148129\tvalid_1's rmse: 0.418711\n",
      "[18000]\ttraining's rmse: 0.143184\tvalid_1's rmse: 0.417814\n",
      "[19000]\ttraining's rmse: 0.138829\tvalid_1's rmse: 0.41694\n",
      "[20000]\ttraining's rmse: 0.134701\tvalid_1's rmse: 0.416271\n",
      "[21000]\ttraining's rmse: 0.130881\tvalid_1's rmse: 0.415629\n",
      "[22000]\ttraining's rmse: 0.127058\tvalid_1's rmse: 0.414989\n",
      "[23000]\ttraining's rmse: 0.123496\tvalid_1's rmse: 0.414605\n",
      "[24000]\ttraining's rmse: 0.120049\tvalid_1's rmse: 0.414144\n",
      "[25000]\ttraining's rmse: 0.116814\tvalid_1's rmse: 0.413626\n",
      "[26000]\ttraining's rmse: 0.113698\tvalid_1's rmse: 0.413207\n",
      "[27000]\ttraining's rmse: 0.110705\tvalid_1's rmse: 0.412867\n",
      "[28000]\ttraining's rmse: 0.107805\tvalid_1's rmse: 0.412559\n",
      "[29000]\ttraining's rmse: 0.1053\tvalid_1's rmse: 0.412267\n",
      "[30000]\ttraining's rmse: 0.102718\tvalid_1's rmse: 0.412032\n",
      "[31000]\ttraining's rmse: 0.100248\tvalid_1's rmse: 0.411868\n",
      "[32000]\ttraining's rmse: 0.0980516\tvalid_1's rmse: 0.411735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33000]\ttraining's rmse: 0.0958297\tvalid_1's rmse: 0.411498\n",
      "[34000]\ttraining's rmse: 0.0936262\tvalid_1's rmse: 0.411264\n",
      "[35000]\ttraining's rmse: 0.0916387\tvalid_1's rmse: 0.411232\n",
      "[36000]\ttraining's rmse: 0.0895695\tvalid_1's rmse: 0.411015\n",
      "[37000]\ttraining's rmse: 0.0877817\tvalid_1's rmse: 0.410929\n",
      "[38000]\ttraining's rmse: 0.0859051\tvalid_1's rmse: 0.4108\n",
      "[39000]\ttraining's rmse: 0.0841517\tvalid_1's rmse: 0.410672\n",
      "[40000]\ttraining's rmse: 0.0825617\tvalid_1's rmse: 0.410535\n",
      "[41000]\ttraining's rmse: 0.0809431\tvalid_1's rmse: 0.410433\n",
      "[42000]\ttraining's rmse: 0.0793239\tvalid_1's rmse: 0.410367\n",
      "[43000]\ttraining's rmse: 0.0778284\tvalid_1's rmse: 0.410234\n",
      "[44000]\ttraining's rmse: 0.0763442\tvalid_1's rmse: 0.410229\n",
      "[45000]\ttraining's rmse: 0.0749449\tvalid_1's rmse: 0.410184\n",
      "[46000]\ttraining's rmse: 0.0736356\tvalid_1's rmse: 0.410075\n",
      "[47000]\ttraining's rmse: 0.0723646\tvalid_1's rmse: 0.410023\n",
      "[48000]\ttraining's rmse: 0.0711198\tvalid_1's rmse: 0.409989\n",
      "[49000]\ttraining's rmse: 0.0698808\tvalid_1's rmse: 0.409966\n",
      "[50000]\ttraining's rmse: 0.0687301\tvalid_1's rmse: 0.410009\n",
      "Early stopping, best iteration is:\n",
      "[49123]\ttraining's rmse: 0.0697355\tvalid_1's rmse: 0.409953\n",
      "Start 4 fold\n",
      "--------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's rmse: 0.501652\tvalid_1's rmse: 0.619756\n",
      "[2000]\ttraining's rmse: 0.376191\tvalid_1's rmse: 0.520865\n",
      "[3000]\ttraining's rmse: 0.318803\tvalid_1's rmse: 0.48061\n",
      "[4000]\ttraining's rmse: 0.28625\tvalid_1's rmse: 0.461535\n",
      "[5000]\ttraining's rmse: 0.261823\tvalid_1's rmse: 0.4476\n",
      "[6000]\ttraining's rmse: 0.244797\tvalid_1's rmse: 0.440066\n",
      "[7000]\ttraining's rmse: 0.229947\tvalid_1's rmse: 0.43385\n",
      "[8000]\ttraining's rmse: 0.217482\tvalid_1's rmse: 0.42919\n",
      "[9000]\ttraining's rmse: 0.206653\tvalid_1's rmse: 0.42539\n",
      "[10000]\ttraining's rmse: 0.197083\tvalid_1's rmse: 0.422826\n",
      "[11000]\ttraining's rmse: 0.18804\tvalid_1's rmse: 0.420784\n",
      "[12000]\ttraining's rmse: 0.180334\tvalid_1's rmse: 0.418924\n",
      "[13000]\ttraining's rmse: 0.17298\tvalid_1's rmse: 0.417221\n",
      "[14000]\ttraining's rmse: 0.16622\tvalid_1's rmse: 0.415865\n",
      "[15000]\ttraining's rmse: 0.160007\tvalid_1's rmse: 0.414384\n",
      "[16000]\ttraining's rmse: 0.154256\tvalid_1's rmse: 0.413396\n",
      "[17000]\ttraining's rmse: 0.149152\tvalid_1's rmse: 0.412608\n",
      "[18000]\ttraining's rmse: 0.144041\tvalid_1's rmse: 0.411683\n",
      "[19000]\ttraining's rmse: 0.139583\tvalid_1's rmse: 0.410993\n",
      "[20000]\ttraining's rmse: 0.135393\tvalid_1's rmse: 0.410284\n",
      "[21000]\ttraining's rmse: 0.13114\tvalid_1's rmse: 0.409698\n",
      "[22000]\ttraining's rmse: 0.127325\tvalid_1's rmse: 0.409217\n",
      "[23000]\ttraining's rmse: 0.123698\tvalid_1's rmse: 0.408879\n",
      "[24000]\ttraining's rmse: 0.120201\tvalid_1's rmse: 0.408319\n",
      "[25000]\ttraining's rmse: 0.116889\tvalid_1's rmse: 0.407897\n",
      "[26000]\ttraining's rmse: 0.113734\tvalid_1's rmse: 0.407509\n",
      "[27000]\ttraining's rmse: 0.110883\tvalid_1's rmse: 0.40727\n",
      "[28000]\ttraining's rmse: 0.108092\tvalid_1's rmse: 0.406999\n",
      "[29000]\ttraining's rmse: 0.105401\tvalid_1's rmse: 0.406863\n",
      "[30000]\ttraining's rmse: 0.102833\tvalid_1's rmse: 0.406607\n",
      "[31000]\ttraining's rmse: 0.100366\tvalid_1's rmse: 0.406367\n",
      "[32000]\ttraining's rmse: 0.0980873\tvalid_1's rmse: 0.406207\n",
      "[33000]\ttraining's rmse: 0.0957593\tvalid_1's rmse: 0.406087\n",
      "[34000]\ttraining's rmse: 0.0935053\tvalid_1's rmse: 0.405975\n",
      "[35000]\ttraining's rmse: 0.0914449\tvalid_1's rmse: 0.405842\n",
      "[36000]\ttraining's rmse: 0.0893755\tvalid_1's rmse: 0.405696\n",
      "[37000]\ttraining's rmse: 0.0873925\tvalid_1's rmse: 0.405573\n",
      "[38000]\ttraining's rmse: 0.0855457\tvalid_1's rmse: 0.405551\n",
      "[39000]\ttraining's rmse: 0.083782\tvalid_1's rmse: 0.405484\n",
      "[40000]\ttraining's rmse: 0.0821609\tvalid_1's rmse: 0.405428\n",
      "[41000]\ttraining's rmse: 0.0805219\tvalid_1's rmse: 0.405439\n",
      "[42000]\ttraining's rmse: 0.0788776\tvalid_1's rmse: 0.405358\n",
      "[43000]\ttraining's rmse: 0.0773255\tvalid_1's rmse: 0.405268\n",
      "[44000]\ttraining's rmse: 0.0758337\tvalid_1's rmse: 0.405263\n",
      "Early stopping, best iteration is:\n",
      "[43204]\ttraining's rmse: 0.0769809\tvalid_1's rmse: 0.405235\n",
      "Start 5 fold\n",
      "--------------------\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's rmse: 0.510515\tvalid_1's rmse: 0.555333\n",
      "[2000]\ttraining's rmse: 0.378163\tvalid_1's rmse: 0.46297\n",
      "[3000]\ttraining's rmse: 0.319483\tvalid_1's rmse: 0.428355\n",
      "[4000]\ttraining's rmse: 0.286668\tvalid_1's rmse: 0.412476\n",
      "[5000]\ttraining's rmse: 0.262642\tvalid_1's rmse: 0.402255\n",
      "[6000]\ttraining's rmse: 0.246093\tvalid_1's rmse: 0.397383\n",
      "[7000]\ttraining's rmse: 0.231621\tvalid_1's rmse: 0.393322\n",
      "[8000]\ttraining's rmse: 0.219259\tvalid_1's rmse: 0.390503\n",
      "[9000]\ttraining's rmse: 0.208685\tvalid_1's rmse: 0.388271\n",
      "[10000]\ttraining's rmse: 0.199002\tvalid_1's rmse: 0.386364\n",
      "[11000]\ttraining's rmse: 0.190449\tvalid_1's rmse: 0.384391\n",
      "[12000]\ttraining's rmse: 0.182722\tvalid_1's rmse: 0.382683\n",
      "[13000]\ttraining's rmse: 0.175539\tvalid_1's rmse: 0.381166\n",
      "[14000]\ttraining's rmse: 0.168924\tvalid_1's rmse: 0.380019\n",
      "[15000]\ttraining's rmse: 0.162838\tvalid_1's rmse: 0.379188\n",
      "[16000]\ttraining's rmse: 0.157247\tvalid_1's rmse: 0.378392\n",
      "[17000]\ttraining's rmse: 0.152241\tvalid_1's rmse: 0.37787\n",
      "[18000]\ttraining's rmse: 0.146899\tvalid_1's rmse: 0.37689\n",
      "[19000]\ttraining's rmse: 0.142113\tvalid_1's rmse: 0.376286\n",
      "[20000]\ttraining's rmse: 0.137645\tvalid_1's rmse: 0.375896\n",
      "[21000]\ttraining's rmse: 0.133194\tvalid_1's rmse: 0.375292\n",
      "[22000]\ttraining's rmse: 0.129007\tvalid_1's rmse: 0.374739\n",
      "[23000]\ttraining's rmse: 0.125249\tvalid_1's rmse: 0.374243\n",
      "[24000]\ttraining's rmse: 0.121793\tvalid_1's rmse: 0.373846\n",
      "[25000]\ttraining's rmse: 0.118338\tvalid_1's rmse: 0.373447\n",
      "[26000]\ttraining's rmse: 0.115161\tvalid_1's rmse: 0.373151\n",
      "[27000]\ttraining's rmse: 0.112049\tvalid_1's rmse: 0.372895\n",
      "[28000]\ttraining's rmse: 0.109181\tvalid_1's rmse: 0.37255\n",
      "[29000]\ttraining's rmse: 0.106385\tvalid_1's rmse: 0.372458\n",
      "[30000]\ttraining's rmse: 0.103669\tvalid_1's rmse: 0.372233\n",
      "[31000]\ttraining's rmse: 0.101144\tvalid_1's rmse: 0.372093\n",
      "[32000]\ttraining's rmse: 0.0988641\tvalid_1's rmse: 0.371927\n",
      "[33000]\ttraining's rmse: 0.0965159\tvalid_1's rmse: 0.371734\n",
      "[34000]\ttraining's rmse: 0.0943142\tvalid_1's rmse: 0.371572\n",
      "[35000]\ttraining's rmse: 0.0922039\tvalid_1's rmse: 0.371413\n",
      "[36000]\ttraining's rmse: 0.0900521\tvalid_1's rmse: 0.371326\n",
      "[37000]\ttraining's rmse: 0.0881601\tvalid_1's rmse: 0.371214\n",
      "[38000]\ttraining's rmse: 0.0863564\tvalid_1's rmse: 0.371066\n",
      "[39000]\ttraining's rmse: 0.0847169\tvalid_1's rmse: 0.370972\n",
      "[40000]\ttraining's rmse: 0.0830687\tvalid_1's rmse: 0.370967\n",
      "[41000]\ttraining's rmse: 0.0814299\tvalid_1's rmse: 0.370913\n"
     ]
    }
   ],
   "source": [
    "exec_single = True\n",
    "\n",
    "if exec_single:\n",
    "    oof, y_pred, models = train_lgb(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        StratifiedGroupKFold(n_splits=5, random_state=0).split(X_train, y=stratified_y, groups=proc.groups)\n",
    "    )\n",
    "else:\n",
    "    # seed averaging\n",
    "    n = 10\n",
    "    oofs = np.zeros((len(X_train), n))\n",
    "    y_preds = np.zeros((len(X_test), n))\n",
    "\n",
    "    for i in range(n):\n",
    "        oof, y_pred, models = train_lgb(X_train, y_train, X_test, GroupKFold(n_splits=5).split(X_train, groups=proc.groups), seed=i)\n",
    "        oofs[:, i] = oof\n",
    "        y_preds[:, i] = y_pred\n",
    "\n",
    "    oof = oofs.mean(axis=1)\n",
    "    y_pred = y_preds.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-14T12:37:28.252Z"
    }
   },
   "outputs": [],
   "source": [
    "oof = np.where(oof < 0, 0, oof)\n",
    "y_pred = np.where(y_pred < 0, 0, y_pred)\n",
    "\n",
    "y_train = np.expm1(y_train)\n",
    "oof = np.expm1(oof)\n",
    "y_pred = np.expm1(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-14T12:37:28.253Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mean_squared_log_error(y_train, oof) ** .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-14T12:37:28.255Z"
    }
   },
   "outputs": [],
   "source": [
    "submit['Global_Sales'] = y_pred\n",
    "submit.to_csv('../output/20201214_latesub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-14T12:37:28.256Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "#sns.distplot(np.log1p(y_train), label='Ground Truth')\n",
    "sns.distplot(np.log1p(y_pred), label='Test Predict')\n",
    "sns.distplot(np.log1p(oof), label='Out Of Fold')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-14T12:37:28.258Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_importance(models, X_train):\n",
    "    \"\"\"lightGBM の model 配列の feature importance を plot する\n",
    "    CVごとのブレを boxen plot として表現します.\n",
    "\n",
    "    args:\n",
    "        models:\n",
    "            List of lightGBM models\n",
    "        feat_train_df:\n",
    "            学習時に使った DataFrame\n",
    "    \"\"\"\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    for i, model in enumerate(models):\n",
    "        _df = pd.DataFrame()\n",
    "        _df['feature_importance'] = model.feature_importance(importance_type='gain')\n",
    "        _df['column'] = X_train.columns\n",
    "        _df['fold'] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, _df], axis=0, ignore_index=True)\n",
    "\n",
    "    order = feature_importance_df.groupby('column')\\\n",
    "        .sum()[['feature_importance']]\\\n",
    "        .sort_values('feature_importance', ascending=False).index[:50]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, max(6, len(order) * .2)))\n",
    "    sns.boxenplot(\n",
    "        data=feature_importance_df,\n",
    "        y='column',\n",
    "        x='feature_importance',\n",
    "        order=order,\n",
    "        ax=ax,\n",
    "        palette='viridis',\n",
    "        orient='h'\n",
    "    )\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.grid()\n",
    "    fig.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "visualize_importance(models, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-14T12:37:28.260Z"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump((oof, y_pred), '../output/LGB_oof_ypred.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
